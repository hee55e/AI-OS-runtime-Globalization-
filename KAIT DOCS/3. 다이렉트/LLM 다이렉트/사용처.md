# LLM 다이렉트 사용처

> 코드 동기 기준: 2026-02-03
> 원칙: 문서보다 코드가 우선입니다.

## 현재 구현
- LLM Direct는 ProcessorType `llm`, Graph `llm_node`, Binding AI, OpenAI 호환 API에서 공통 사용됩니다.
- Provider는 manifest/registry 기반으로 로드되며 OpenAI/Anthropic/Google 등 구현체가 존재합니다.
- Google provider는 SDK 경고(`TrafficType`)를 코드에서 억제 처리하고 있습니다.

## 프론트엔드 연결
- 모델/프로바이더 선택 UI는 Processor Editor, Node 속성 패널에서 사용됩니다.
- Provider schema API로 동적 폼을 구성합니다.

## 백엔드 연결
- 팩토리: `kait_os/services/llm/llm_factory.py`
- 베이스: `kait_os/core/llm_direct/base.py`
- Provider registry: `kait_os/core/llm_direct/providers/registry.py`
- Google provider: `kait_os/core/llm_direct/providers/google/provider.py`

## TODO
- [ ] 모델별 제약(토큰/툴/이미지)을 UI에서 사전 검증
- [ ] 프로바이더 공통 진단(키/네트워크/권한) 테스트 버튼 제공

## 관련 코드
- `kait_os/services/llm/llm_factory.py`
- `kait_os/core/llm_direct/providers`
- `kait_os/routers/system/provider_schemas.py`
- `kait_os/core/llm_direct/providers/google/provider.py`
